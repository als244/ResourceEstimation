{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "41bb2caa-cbd9-444d-acfa-aee55f467148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90461df5-aec3-4279-ab5b-61e3b251fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aebea274-7969-4923-913f-9d10c0a139b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_DIR = \"/mnt/storage/research/princeton/resource_estimation/gemm/3090/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bb65906e-2b83-40c2-816f-84f525e1ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROFILE_DIR + \"profiling_df.pickle\", \"rb\") as in_file:\n",
    "    df = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75e0f56a-35e2-4ed1-bff4-3a54a4f31949",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROFILE_DIR + \"error_files_list.pickle\", \"rb\") as in_file:\n",
    "    error_files = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86907d48-aa22-4951-a831-82109a0cdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "df = df.loc[:, df.columns.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "687932e9-7014-4ba8-ab08-373a94f2c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "### important columns for now\n",
    "key_cols = ['M', 'K', 'N', 'Duration (nsecond)', 'Compute (SM) Throughput (%)', 'Memory Throughput (%)', 'Memory Throughput (byte/second)', 'DRAM Throughput (%)', 'Mem Busy (%)', 'Max Bandwidth (%)', 'Mem Pipes Busy (%)', 'Theoretical Occupancy (%)', 'Achieved Occupancy (%)', \n",
    "            'Elapsed Cycles (cycle)', 'SM Active Cycles (cycle)', 'SM: Pipe Tensor Cycles Active (%)',\n",
    "            'Executed Ipc Active (inst/cycle)', 'Executed Ipc Elapsed (inst/cycle)', 'Issue Slots Busy (%)', 'Issued Ipc Active (inst/cycle)', 'SM Busy (%)', 'Tensor (All) (%)', 'ALU (%)', 'FMA (%)', 'FMA (FP16) (%)', 'FP64 (%)', 'FP64 (DMMA) (%)',  \n",
    "            'L1/TEX Cache Throughput (%)', 'L2 Cache Throughput (%)', 'L1/TEX Hit Rate (%)', 'L2 Hit Rate (%)',\n",
    "            'Active Warps Per Scheduler (warp)', 'Eligible Warps Per Scheduler (warp)', 'Theoretical Warps Per Scheduler (warp)', 'GPU Maximum Warps Per Scheduler (warp)', 'Active Warps Per Scheduler (warp)', 'Eligible Warps Per Scheduler (warp)', 'Warp Cycles Per Issued Instruction (cycle)', 'Warp Cycles Per Executed Instruction (cycle)',\n",
    "            'Avg. Executed Instructions Per Scheduler (inst)', 'Executed Instructions (inst)', 'Avg. Issued Instructions Per Scheduler (inst)', 'Issued Instructions (inst)', 'Registers Per Thread (register/thread)', 'Shared Memory Per Block (byte/block)', 'Shared Memory Configuration Size (byte)', 'Driver Shared Memory Per Block (byte/block)', 'Dynamic Shared Memory Per Block (byte/block)', 'Static Shared Memory Per Block (byte/block)', 'Threads (thread)', 'Avg. Threads Executed (thread)', 'Avg. Predicated-On Threads Executed (thread)',\n",
    "            'Theoretical Active Warps per SM (warp)', 'Achieved Active Warps Per SM (warp)',\n",
    "            'L1 Wavefronts Shared Excessive (byte)', 'L2 Theoretical Sectors Global Excessive (byte)', 'Branch Instructions Ratio (%)',\n",
    "            'SM Frequency (cycle/second)', 'DRAM Frequency (cycle/second)', \n",
    "            'Kernel Name', 'Block Size', 'Grid Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c41cf73b-5ecc-4416-9577-a65ad17a5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_key = df[key_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3732998d-93d1-489d-adfe-0c9d5e0e09ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1667204/799244815.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_key[\"Duration (nsecond)\"] = df_key[\"Duration (nsecond)\"].apply(lambda x: x.replace(\",\", \"\")).astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_key[\"Duration (nsecond)\"] = df_key[\"Duration (nsecond)\"].apply(lambda x: x.replace(\",\", \"\")).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b795a21a-cc53-493f-9ef7-d974a03c7e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605864256"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_key[\"Duration (nsecond)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7c2e5b4-0070-4c78-8a95-f481c2ad4c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>K</th>\n",
       "      <th>N</th>\n",
       "      <th>Duration (nsecond)</th>\n",
       "      <th>Compute (SM) Throughput (%)</th>\n",
       "      <th>Memory Throughput (%)</th>\n",
       "      <th>Memory Throughput (byte/second)</th>\n",
       "      <th>DRAM Throughput (%)</th>\n",
       "      <th>Mem Busy (%)</th>\n",
       "      <th>Max Bandwidth (%)</th>\n",
       "      <th>Mem Pipes Busy (%)</th>\n",
       "      <th>Theoretical Occupancy (%)</th>\n",
       "      <th>Achieved Occupancy (%)</th>\n",
       "      <th>Elapsed Cycles (cycle)</th>\n",
       "      <th>SM Active Cycles (cycle)</th>\n",
       "      <th>SM: Pipe Tensor Cycles Active (%)</th>\n",
       "      <th>Executed Ipc Active (inst/cycle)</th>\n",
       "      <th>Executed Ipc Elapsed (inst/cycle)</th>\n",
       "      <th>Issue Slots Busy (%)</th>\n",
       "      <th>Issued Ipc Active (inst/cycle)</th>\n",
       "      <th>SM Busy (%)</th>\n",
       "      <th>Tensor (All) (%)</th>\n",
       "      <th>ALU (%)</th>\n",
       "      <th>FMA (%)</th>\n",
       "      <th>FMA (FP16) (%)</th>\n",
       "      <th>FP64 (%)</th>\n",
       "      <th>FP64 (DMMA) (%)</th>\n",
       "      <th>L1/TEX Cache Throughput (%)</th>\n",
       "      <th>L2 Cache Throughput (%)</th>\n",
       "      <th>L1/TEX Hit Rate (%)</th>\n",
       "      <th>L2 Hit Rate (%)</th>\n",
       "      <th>Active Warps Per Scheduler (warp)</th>\n",
       "      <th>Eligible Warps Per Scheduler (warp)</th>\n",
       "      <th>Theoretical Warps Per Scheduler (warp)</th>\n",
       "      <th>GPU Maximum Warps Per Scheduler (warp)</th>\n",
       "      <th>Active Warps Per Scheduler (warp)</th>\n",
       "      <th>Eligible Warps Per Scheduler (warp)</th>\n",
       "      <th>Warp Cycles Per Issued Instruction (cycle)</th>\n",
       "      <th>Warp Cycles Per Executed Instruction (cycle)</th>\n",
       "      <th>Avg. Executed Instructions Per Scheduler (inst)</th>\n",
       "      <th>Executed Instructions (inst)</th>\n",
       "      <th>Avg. Issued Instructions Per Scheduler (inst)</th>\n",
       "      <th>Issued Instructions (inst)</th>\n",
       "      <th>Registers Per Thread (register/thread)</th>\n",
       "      <th>Shared Memory Per Block (byte/block)</th>\n",
       "      <th>Shared Memory Configuration Size (byte)</th>\n",
       "      <th>Driver Shared Memory Per Block (byte/block)</th>\n",
       "      <th>Dynamic Shared Memory Per Block (byte/block)</th>\n",
       "      <th>Static Shared Memory Per Block (byte/block)</th>\n",
       "      <th>Threads (thread)</th>\n",
       "      <th>Avg. Threads Executed (thread)</th>\n",
       "      <th>Avg. Predicated-On Threads Executed (thread)</th>\n",
       "      <th>Theoretical Active Warps per SM (warp)</th>\n",
       "      <th>Achieved Active Warps Per SM (warp)</th>\n",
       "      <th>L1 Wavefronts Shared Excessive (byte)</th>\n",
       "      <th>L2 Theoretical Sectors Global Excessive (byte)</th>\n",
       "      <th>Branch Instructions Ratio (%)</th>\n",
       "      <th>SM Frequency (cycle/second)</th>\n",
       "      <th>DRAM Frequency (cycle/second)</th>\n",
       "      <th>Kernel Name</th>\n",
       "      <th>Block Size</th>\n",
       "      <th>Grid Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>6528</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3.30</td>\n",
       "      <td>22,058,823,529.41</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.79</td>\n",
       "      <td>16.67</td>\n",
       "      <td>8.34</td>\n",
       "      <td>8,597</td>\n",
       "      <td>308.68</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>20.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>20.64</td>\n",
       "      <td>17.32</td>\n",
       "      <td>16.18</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.36</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0</td>\n",
       "      <td>72.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.89</td>\n",
       "      <td>62.49</td>\n",
       "      <td>20,496</td>\n",
       "      <td>63.71</td>\n",
       "      <td>20,896</td>\n",
       "      <td>100</td>\n",
       "      <td>50,176</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>49,152</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1,664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,316,198,354.34</td>\n",
       "      <td>8,967,320,261.44</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(128, 1, 1)</td>\n",
       "      <td>(4, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>8416</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.88</td>\n",
       "      <td>31,482,889,733.84</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.03</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.27</td>\n",
       "      <td>10,932</td>\n",
       "      <td>435.04</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.03</td>\n",
       "      <td>21.27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>22.96</td>\n",
       "      <td>22.96</td>\n",
       "      <td>18.57</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.93</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0</td>\n",
       "      <td>59.06</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.24</td>\n",
       "      <td>91.12</td>\n",
       "      <td>29,888</td>\n",
       "      <td>92.54</td>\n",
       "      <td>30,352</td>\n",
       "      <td>102</td>\n",
       "      <td>99,328</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>98,304</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,298,156,572.51</td>\n",
       "      <td>8,861,850,443.60</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(128, 1, 1)</td>\n",
       "      <td>(4, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>12128</td>\n",
       "      <td>1.27</td>\n",
       "      <td>5.70</td>\n",
       "      <td>48,221,635,883.91</td>\n",
       "      <td>5.70</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.21</td>\n",
       "      <td>8.33</td>\n",
       "      <td>7.99</td>\n",
       "      <td>15,715</td>\n",
       "      <td>700.34</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>28.53</td>\n",
       "      <td>28.53</td>\n",
       "      <td>17.66</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.06</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0</td>\n",
       "      <td>65.57</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.59</td>\n",
       "      <td>145.76</td>\n",
       "      <td>47,808</td>\n",
       "      <td>147.17</td>\n",
       "      <td>48,272</td>\n",
       "      <td>102</td>\n",
       "      <td>99,328</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>98,304</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,295,267,150.40</td>\n",
       "      <td>8,816,182,937.55</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(128, 1, 1)</td>\n",
       "      <td>(4, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>19360</td>\n",
       "      <td>1.57</td>\n",
       "      <td>6.54</td>\n",
       "      <td>56,310,743,801.65</td>\n",
       "      <td>6.54</td>\n",
       "      <td>5.77</td>\n",
       "      <td>6.54</td>\n",
       "      <td>1.36</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.08</td>\n",
       "      <td>25,471</td>\n",
       "      <td>1,177.28</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>33.94</td>\n",
       "      <td>33.94</td>\n",
       "      <td>17.80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.89</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0</td>\n",
       "      <td>52.69</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.46</td>\n",
       "      <td>255.02</td>\n",
       "      <td>83,648</td>\n",
       "      <td>256.44</td>\n",
       "      <td>84,112</td>\n",
       "      <td>102</td>\n",
       "      <td>99,328</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>98,304</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,315,370,425.03</td>\n",
       "      <td>8,965,289,256.20</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(128, 1, 1)</td>\n",
       "      <td>(4, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>32672</td>\n",
       "      <td>1.80</td>\n",
       "      <td>7.56</td>\n",
       "      <td>67,200,783,545.54</td>\n",
       "      <td>7.56</td>\n",
       "      <td>6.47</td>\n",
       "      <td>7.56</td>\n",
       "      <td>1.48</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.32</td>\n",
       "      <td>44,464</td>\n",
       "      <td>2,077.89</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.04</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>38.46</td>\n",
       "      <td>38.46</td>\n",
       "      <td>18.35</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.93</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0</td>\n",
       "      <td>51.24</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.38</td>\n",
       "      <td>473.56</td>\n",
       "      <td>155,328</td>\n",
       "      <td>474.98</td>\n",
       "      <td>155,792</td>\n",
       "      <td>102</td>\n",
       "      <td>99,328</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>98,304</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,360,632,083.39</td>\n",
       "      <td>9,256,284,688.21</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(128, 1, 1)</td>\n",
       "      <td>(4, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>65536</td>\n",
       "      <td>512</td>\n",
       "      <td>16384</td>\n",
       "      <td>22485344</td>\n",
       "      <td>41.80</td>\n",
       "      <td>63.90</td>\n",
       "      <td>390,605,911,477.27</td>\n",
       "      <td>42.89</td>\n",
       "      <td>63.90</td>\n",
       "      <td>54.81</td>\n",
       "      <td>18.23</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.66</td>\n",
       "      <td>31,338,257</td>\n",
       "      <td>31,222,023.13</td>\n",
       "      <td>41.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>16.03</td>\n",
       "      <td>0.64</td>\n",
       "      <td>41.94</td>\n",
       "      <td>41.94</td>\n",
       "      <td>11.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.80</td>\n",
       "      <td>63.90</td>\n",
       "      <td>0</td>\n",
       "      <td>92.70</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.22</td>\n",
       "      <td>12.43</td>\n",
       "      <td>12.43</td>\n",
       "      <td>5,005,511.80</td>\n",
       "      <td>1,641,807,872</td>\n",
       "      <td>5,005,555.62</td>\n",
       "      <td>1,641,822,242</td>\n",
       "      <td>244</td>\n",
       "      <td>74,752</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>73,728</td>\n",
       "      <td>0</td>\n",
       "      <td>8,388,608</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>138,410,776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,393,256,018.55</td>\n",
       "      <td>9,487,593,222.20</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(256, 1, 1)</td>\n",
       "      <td>(1024, 32, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>65536</td>\n",
       "      <td>1024</td>\n",
       "      <td>16384</td>\n",
       "      <td>41793632</td>\n",
       "      <td>44.90</td>\n",
       "      <td>63.76</td>\n",
       "      <td>382,827,506,735.95</td>\n",
       "      <td>41.97</td>\n",
       "      <td>63.76</td>\n",
       "      <td>58.86</td>\n",
       "      <td>17.84</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.61</td>\n",
       "      <td>58,345,415</td>\n",
       "      <td>58,358,652.52</td>\n",
       "      <td>44.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>15.69</td>\n",
       "      <td>0.63</td>\n",
       "      <td>44.88</td>\n",
       "      <td>44.88</td>\n",
       "      <td>10.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.28</td>\n",
       "      <td>63.76</td>\n",
       "      <td>0</td>\n",
       "      <td>89.48</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.73</td>\n",
       "      <td>9,155,059.51</td>\n",
       "      <td>3,002,859,520</td>\n",
       "      <td>9,155,107.30</td>\n",
       "      <td>3,002,875,195</td>\n",
       "      <td>244</td>\n",
       "      <td>74,752</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>73,728</td>\n",
       "      <td>0</td>\n",
       "      <td>8,388,608</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>7.97</td>\n",
       "      <td>272,633,708</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,395,698,351.50</td>\n",
       "      <td>9,500,729,552.93</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(256, 1, 1)</td>\n",
       "      <td>(512, 64, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>65536</td>\n",
       "      <td>2048</td>\n",
       "      <td>16384</td>\n",
       "      <td>81544960</td>\n",
       "      <td>46.18</td>\n",
       "      <td>78.00</td>\n",
       "      <td>709,183,350,338.27</td>\n",
       "      <td>78.00</td>\n",
       "      <td>63.04</td>\n",
       "      <td>78.00</td>\n",
       "      <td>17.48</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.62</td>\n",
       "      <td>113,467,799</td>\n",
       "      <td>113,403,295.38</td>\n",
       "      <td>46.18</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>15.51</td>\n",
       "      <td>0.62</td>\n",
       "      <td>46.19</td>\n",
       "      <td>46.19</td>\n",
       "      <td>10.08</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.52</td>\n",
       "      <td>63.04</td>\n",
       "      <td>0</td>\n",
       "      <td>76.41</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.84</td>\n",
       "      <td>17,588,423.80</td>\n",
       "      <td>5,769,003,008</td>\n",
       "      <td>17,588,468.62</td>\n",
       "      <td>5,769,017,709</td>\n",
       "      <td>244</td>\n",
       "      <td>74,752</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>73,728</td>\n",
       "      <td>0</td>\n",
       "      <td>8,388,608</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>7.98</td>\n",
       "      <td>541,064,292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,390,982,997.07</td>\n",
       "      <td>9,470,749,943.75</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(256, 1, 1)</td>\n",
       "      <td>(1024, 32, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>65536</td>\n",
       "      <td>4096</td>\n",
       "      <td>16384</td>\n",
       "      <td>158803968</td>\n",
       "      <td>47.40</td>\n",
       "      <td>71.00</td>\n",
       "      <td>645,698,378,116.09</td>\n",
       "      <td>71.00</td>\n",
       "      <td>63.43</td>\n",
       "      <td>71.00</td>\n",
       "      <td>17.49</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.65</td>\n",
       "      <td>221,048,230</td>\n",
       "      <td>220,843,158.68</td>\n",
       "      <td>47.40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>15.56</td>\n",
       "      <td>0.62</td>\n",
       "      <td>47.43</td>\n",
       "      <td>47.43</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.03</td>\n",
       "      <td>63.43</td>\n",
       "      <td>0</td>\n",
       "      <td>75.19</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>12.86</td>\n",
       "      <td>12.86</td>\n",
       "      <td>34,365,639.80</td>\n",
       "      <td>11,271,929,856</td>\n",
       "      <td>34,365,684.10</td>\n",
       "      <td>11,271,944,384</td>\n",
       "      <td>244</td>\n",
       "      <td>74,752</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>73,728</td>\n",
       "      <td>0</td>\n",
       "      <td>8,388,608</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>7.99</td>\n",
       "      <td>1,077,935,528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1,391,625,112.65</td>\n",
       "      <td>9,473,703,696.54</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(256, 1, 1)</td>\n",
       "      <td>(1024, 32, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>65536</td>\n",
       "      <td>8192</td>\n",
       "      <td>16384</td>\n",
       "      <td>605862880</td>\n",
       "      <td>49.57</td>\n",
       "      <td>32.98</td>\n",
       "      <td>207,295,955,810.99</td>\n",
       "      <td>22.74</td>\n",
       "      <td>32.98</td>\n",
       "      <td>32.64</td>\n",
       "      <td>9.03</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>845,354,027</td>\n",
       "      <td>844,067,219.71</td>\n",
       "      <td>49.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>49.64</td>\n",
       "      <td>49.64</td>\n",
       "      <td>7.95</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.98</td>\n",
       "      <td>32.98</td>\n",
       "      <td>0</td>\n",
       "      <td>84.44</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>15.91</td>\n",
       "      <td>15.91</td>\n",
       "      <td>106,115,571.51</td>\n",
       "      <td>34,805,907,456</td>\n",
       "      <td>106,115,614.51</td>\n",
       "      <td>34,805,921,560</td>\n",
       "      <td>236</td>\n",
       "      <td>74,752</td>\n",
       "      <td>102,400</td>\n",
       "      <td>1,024</td>\n",
       "      <td>73,728</td>\n",
       "      <td>0</td>\n",
       "      <td>8,388,608</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2,151,676,280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,395,128,768.36</td>\n",
       "      <td>9,494,725,257.53</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_tensorop_s1688...</td>\n",
       "      <td>(256, 1, 1)</td>\n",
       "      <td>(512, 64, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         M     K      N  Duration (nsecond) Compute (SM) Throughput (%) Memory Throughput (%) Memory Throughput (byte/second) DRAM Throughput (%) Mem Busy (%) Max Bandwidth (%) Mem Pipes Busy (%) Theoretical Occupancy (%) Achieved Occupancy (%) Elapsed Cycles (cycle) SM Active Cycles (cycle) SM: Pipe Tensor Cycles Active (%) Executed Ipc Active (inst/cycle) Executed Ipc Elapsed (inst/cycle) Issue Slots Busy (%) Issued Ipc Active (inst/cycle) SM Busy (%) Tensor (All) (%) ALU (%) FMA (%) FMA (FP16) (%) FP64 (%) FP64 (DMMA) (%) L1/TEX Cache Throughput (%) L2 Cache Throughput (%) L1/TEX Hit Rate (%) L2 Hit Rate (%) Active Warps Per Scheduler (warp) Eligible Warps Per Scheduler (warp) Theoretical Warps Per Scheduler (warp) GPU Maximum Warps Per Scheduler (warp) Active Warps Per Scheduler (warp) Eligible Warps Per Scheduler (warp) Warp Cycles Per Issued Instruction (cycle) Warp Cycles Per Executed Instruction (cycle) Avg. Executed Instructions Per Scheduler (inst)  \\\n",
       "0      128   128    128                6528                        0.79                  3.30               22,058,823,529.41                2.56         3.30              2.56               0.79                     16.67                   8.34                  8,597                   308.68                              0.79                             0.81                              0.03                20.64                           0.83       20.64            17.32   16.18    2.62              0        0               0                       32.36                    3.30                   0           72.94                              0.99                                0.21                                      2                                     12                              0.99                                0.21                                       4.80                                         4.89                                           62.49   \n",
       "1      128   256    128                8416                        1.03                  3.88               31,482,889,733.84                3.70         3.88              3.70               1.03                      8.33                   8.27                 10,932                   435.04                              1.03                             0.84                              0.03                21.27                           0.85       22.96            22.96   18.57    1.65              0        0               0                       45.93                    3.88                   0           59.06                              1.07                                0.21                                      1                                     12                              1.07                                0.21                                       5.16                                         5.24                                           91.12   \n",
       "2      128   512    128               12128                        1.27                  5.70               48,221,635,883.91                5.70         4.98              5.70               1.21                      8.33                   7.99                 15,715                   700.34                              1.27                             0.83                              0.04                21.01                           0.84       28.53            28.53   17.66    1.25              0        0               0                       57.06                    4.98                   0           65.57                              0.95                                0.21                                      1                                     12                              0.95                                0.21                                       4.54                                         4.59                                          145.76   \n",
       "3      128  1024    128               19360                        1.57                  6.54               56,310,743,801.65                6.54         5.77              6.54               1.36                      8.33                   8.08                 25,471                 1,177.28                              1.57                             0.87                              0.04                21.78                           0.87       33.94            33.94   17.80    1.01              0        0               0                       67.89                    5.77                   0           52.69                              0.98                                0.22                                      1                                     12                              0.98                                0.22                                       4.44                                         4.46                                          255.02   \n",
       "4      128  2048    128               32672                        1.80                  7.56               67,200,783,545.54                7.56         6.47              7.56               1.48                      8.33                   8.32                 44,464                 2,077.89                              1.80                             0.91                              0.04                22.86                           0.91       38.46            38.46   18.35    0.87              0        0               0                       76.93                    6.47                   0           51.24                              1.00                                0.23                                      1                                     12                              1.00                                0.23                                       4.36                                         4.38                                          473.56   \n",
       "..     ...   ...    ...                 ...                         ...                   ...                             ...                 ...          ...               ...                ...                       ...                    ...                    ...                      ...                               ...                              ...                               ...                  ...                            ...         ...              ...     ...     ...            ...      ...             ...                         ...                     ...                 ...             ...                               ...                                 ...                                    ...                                    ...                               ...                                 ...                                        ...                                          ...                                             ...   \n",
       "894  65536   512  16384            22485344                       41.80                 63.90              390,605,911,477.27               42.89        63.90             54.81              18.23                     16.67                  16.66             31,338,257            31,222,023.13                             41.80                             0.64                              0.64                16.03                           0.64       41.94            41.94   11.04    0.97              0        0               0                       41.80                   63.90                   0           92.70                              1.99                                0.22                                      2                                     12                              1.99                                0.22                                      12.43                                        12.43                                    5,005,511.80   \n",
       "895  65536  1024  16384            41793632                       44.90                 63.76              382,827,506,735.95               41.97        63.76             58.86              17.84                     16.67                  16.61             58,345,415            58,358,652.52                             44.90                             0.63                              0.63                15.69                           0.63       44.88            44.88   10.32    0.70              0        0               0                       39.28                   63.76                   0           89.48                              2.01                                0.21                                      2                                     12                              2.01                                0.21                                      12.73                                        12.73                                    9,155,059.51   \n",
       "896  65536  2048  16384            81544960                       46.18                 78.00              709,183,350,338.27               78.00        63.04             78.00              17.48                     16.67                  16.62            113,467,799           113,403,295.38                             46.18                             0.62                              0.62                15.51                           0.62       46.19            46.19   10.08    0.54              0        0               0                       37.52                   63.04                   0           76.41                              2.00                                0.21                                      2                                     12                              2.00                                0.21                                      12.84                                        12.84                                   17,588,423.80   \n",
       "897  65536  4096  16384           158803968                       47.40                 71.00              645,698,378,116.09               71.00        63.43             71.00              17.49                     16.67                  16.65            221,048,230           220,843,158.68                             47.40                             0.62                              0.62                15.56                           0.62       47.43            47.43    9.99    0.46              0        0               0                       37.03                   63.43                   0           75.19                              2.00                                0.21                                      2                                     12                              2.00                                0.21                                      12.86                                        12.86                                   34,365,639.80   \n",
       "898  65536  8192  16384           605862880                       49.57                 32.98              207,295,955,810.99               22.74        32.98             32.64               9.03                     16.67                  16.67            845,354,027           844,067,219.71                             49.57                             0.50                              0.50                12.57                           0.50       49.64            49.64    7.95    3.28              0        0               0                       18.98                   32.98                   0           84.44                              2.00                                0.16                                      2                                     12                              2.00                                0.16                                      15.91                                        15.91                                  106,115,571.51   \n",
       "\n",
       "    Executed Instructions (inst) Avg. Issued Instructions Per Scheduler (inst) Issued Instructions (inst) Registers Per Thread (register/thread) Shared Memory Per Block (byte/block) Shared Memory Configuration Size (byte) Driver Shared Memory Per Block (byte/block) Dynamic Shared Memory Per Block (byte/block) Static Shared Memory Per Block (byte/block) Threads (thread) Avg. Threads Executed (thread) Avg. Predicated-On Threads Executed (thread) Theoretical Active Warps per SM (warp) Achieved Active Warps Per SM (warp) L1 Wavefronts Shared Excessive (byte) L2 Theoretical Sectors Global Excessive (byte) Branch Instructions Ratio (%) SM Frequency (cycle/second) DRAM Frequency (cycle/second)                                        Kernel Name   Block Size      Grid Size  \n",
       "0                         20,496                                         63.71                     20,896                                    100                               50,176                                 102,400                                       1,024                                       49,152                                           0              512                             32                                           30                                      8                                4.00                                 1,664                                              0                          0.01            1,316,198,354.34              8,967,320,261.44  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (128, 1, 1)      (4, 1, 1)  \n",
       "1                         29,888                                         92.54                     30,352                                    102                               99,328                                 102,400                                       1,024                                       98,304                                           0              512                             32                                           30                                      4                                3.97                                     0                                              0                          0.01            1,298,156,572.51              8,861,850,443.60  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (128, 1, 1)      (4, 1, 1)  \n",
       "2                         47,808                                        147.17                     48,272                                    102                               99,328                                 102,400                                       1,024                                       98,304                                           0              512                             32                                           30                                      4                                3.84                                     0                                              0                          0.01            1,295,267,150.40              8,816,182,937.55  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (128, 1, 1)      (4, 1, 1)  \n",
       "3                         83,648                                        256.44                     84,112                                    102                               99,328                                 102,400                                       1,024                                       98,304                                           0              512                             32                                           30                                      4                                3.88                                     0                                              0                          0.01            1,315,370,425.03              8,965,289,256.20  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (128, 1, 1)      (4, 1, 1)  \n",
       "4                        155,328                                        474.98                    155,792                                    102                               99,328                                 102,400                                       1,024                                       98,304                                           0              512                             32                                           30                                      4                                3.99                                     0                                              0                          0.01            1,360,632,083.39              9,256,284,688.21  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (128, 1, 1)      (4, 1, 1)  \n",
       "..                           ...                                           ...                        ...                                    ...                                  ...                                     ...                                         ...                                          ...                                         ...              ...                            ...                                          ...                                    ...                                 ...                                   ...                                            ...                           ...                         ...                           ...                                                ...          ...            ...  \n",
       "894                1,641,807,872                                  5,005,555.62              1,641,822,242                                    244                               74,752                                 102,400                                       1,024                                       73,728                                           0        8,388,608                             32                                           30                                      8                                8.00                           138,410,776                                              0                          0.01            1,393,256,018.55              9,487,593,222.20  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (256, 1, 1)  (1024, 32, 1)  \n",
       "895                3,002,859,520                                  9,155,107.30              3,002,875,195                                    244                               74,752                                 102,400                                       1,024                                       73,728                                           0        8,388,608                             32                                           30                                      8                                7.97                           272,633,708                                              0                          0.01            1,395,698,351.50              9,500,729,552.93  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (256, 1, 1)   (512, 64, 1)  \n",
       "896                5,769,003,008                                 17,588,468.62              5,769,017,709                                    244                               74,752                                 102,400                                       1,024                                       73,728                                           0        8,388,608                             32                                           30                                      8                                7.98                           541,064,292                                              0                          0.01            1,390,982,997.07              9,470,749,943.75  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (256, 1, 1)  (1024, 32, 1)  \n",
       "897               11,271,929,856                                 34,365,684.10             11,271,944,384                                    244                               74,752                                 102,400                                       1,024                                       73,728                                           0        8,388,608                             32                                           30                                      8                                7.99                         1,077,935,528                                              0                          0.01            1,391,625,112.65              9,473,703,696.54  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (256, 1, 1)  (1024, 32, 1)  \n",
       "898               34,805,907,456                                106,115,614.51             34,805,921,560                                    236                               74,752                                 102,400                                       1,024                                       73,728                                           0        8,388,608                             32                                           31                                      8                                8.00                         2,151,676,280                                              0                          0.00            1,395,128,768.36              9,494,725,257.53  void cutlass::Kernel<cutlass_80_tensorop_s1688...  (256, 1, 1)   (512, 64, 1)  \n",
       "\n",
       "[899 rows x 62 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b014c8f-240b-419f-8f18-12f6a8f1a286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
